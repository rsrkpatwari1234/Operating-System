
threads vs process
https://www.personal.kent.edu/%7Ermuhamma/OpSystems/Myos/threads.htm

very nice article : 
https://www.oreilly.com/library/view/understanding-the-linux/0596005652/ch01s06.html

1. Ig talking of such instructions that arehandled directly by the kernel without user intervention

http://web.cs.ucla.edu/classes/winter13/cs111/scribe/4a/ 

Instructions are divided into two categories: the non-privileged instructions and the privileged instructions. A non-privileged instruction is an instruction that any application or user can execute. A privileged instruction, on the other hand, is an instruction that can only be executed in kernel mode. Instructions are divided in this manner because privileged instructions could harm the kernel. 
In any Operating System, it is necessary to have Dual Mode Operation to ensure protection and security of the System from unauthorized or errant users .
Privileged or kernel mode is the processing mode that allows code to have direct access to all hardware and memory in the system. kernel mode means when any process or program wants to use any functionality controlled by Operating System, so in that case, we make a system call to execute any particular set of instructions stored in O.S. So these set of instructions are executed in Kernel mode. Superuser mode means a root user or administrative user who has all the permissions to run or execute any program in the O.S. If a user is not a superuser,i.e. in a guest user mode, it doesn't have permissions to execute everything. So, kernel mode and superuser mode, these two things are different and are not related to each other. In computing, the superuser is a special user account used for system administration. Depending on the operating system (OS), the actual name of this account might be root, administrator, admin or supervisor.
a. protecting the cpu from malicious activity ; kernel allocates processes to the cpu ; else any process may take it over  and shall never  return
b. 
    Memory protection is required to ensure that different processes do not mix with each other’s code or data.
    Every memory address used by a process should be first checked to see whether it falls within the range of memory area that is allocated to the process.
    Two special purpose registers-lower bound register (LBR) and upper bound register (UBR) are used to implement memory protection.
    These registers store the start address and end address of the memory area allocated to a process.

    
    The kernel loads appropriate values in LBR and UBR at execution time.
    The memory protection hardware compares every address used by a process with LBR and UBR registers.
    If the address is smaller than the address in LBR or larger than the address in UBR, a memory protection violation interrupt is generated.
    A page table of the process also stores memory address allocated to that process which maps logical address to its physical address to prevent from accessing any unallocated memory area to be used by that process.
    The relocation register scheme provides an effective way to allow operating system size to change dynamically.

https://www.coursehero.com/file/p17v8jm/Base-Register-variable-fence-register-lower-bound-Bound-Register-the-upper/

 - prevent an attacker from reliably jumping to a vulnerable function in memory
 - Base Register – variable fence register (lower bound) • Bound Register – the upper address limit • Only allow update of base and limit registers in kernel mode • Hardware checks every memory reference – If access out of range, suspend process transfer control to OS

 Refer downloaded slide

 In computing base and bounds refers to a simple form of virtual memory where access to computer memory is controlled by one or a small number of sets of processor registers called base and bounds registers.[1]

In its simplest form each user process is assigned a single contiguous segment of main memory. The operating system loads the physical address of this segment into a base register and its size into a bound register. Virtual addresses seen by the program are added to the contents of the base register to generate the physical address. The address is checked against the contents of the bounds register to prevent a process from accessing memory beyond its assigned segment.

The operating system is not constrained by the hardware and can access all of physical memory.

This technique protects memory used by one process against access or modification by another. By itself it does not protect memory from erroneous access by the owning process. It also allows programs to be easily relocated in memory, since only the base and bounds registers have to be modified when the program is moved. 

c.
Process Implementation

To let the kernel manage processes, each process is represented by a process descriptor that includes information about the current state of the process.

When the kernel stops the execution of a process, it saves the current contents of several processor registers in the process descriptor. These include:

    The program counter (PC) and stack pointer (SP) registers

    The general purpose registers

    The floating point registers

    The processor control registers (Processor Status Word) containing information about the CPU state

    The memory management registers used to keep track of the RAM accessed by the process

When the kernel decides to resume executing a process, it uses the proper process descriptor fields to load the CPU registers. Because the stored value of the program counter points to the instruction following the last instruction executed, the process resumes execution at the point where it was stopped.

When a process is not executing on the CPU, it is waiting for some event. Unix kernels distinguish many wait states, which are usually implemented by queues of process descriptors ; each (possibly empty) queue corresponds to the set of processes waiting for a specific event.

d. malicious activity,close timer , take complete charge of cpu
e. https://www.tutorialspoint.com/operating_system/os_io_hardware.htm 

=========================================================================

1.a.putting the cpu in priviledged mode - allotment of processes to cpu and memory is done in kernel mode by the job scheduler routine of kernel.If this is allowed in user mode then a process may enter an infinite loop and never allot the cpu to other processes.Hence the kernel takes charge of the cpu using hardware timer.When a process is alloted the cpu,the timer interrupt is set and after a particular interval of time,an interrupt is raised to bring the control back to kernel. Thus cpu is alloted to processes in kernel mode and then executed in user mode until the process raises an interrupt or syscall or I/O request.

b. Memory protection is required to ensure that different processes do not mix with each other’s code or data.
    Every memory address used by a process should be first checked to see whether it falls within the range of memory area that is allocated to the process.
    Two special purpose registers-lower bound register (LBR) and upper bound register (UBR) are used to implement memory protection.
    These registers store the start address and end address of the memory area allocated to a process. 
    The kernel loads appropriate values in LBR and UBR at execution time.
    The memory protection hardware compares every address used by a process with LBR and UBR registers.
    If the address is smaller than the address in LBR or larger than the address in UBR, a memory protection violation interrupt is generated.
    A page table of the process also stores memory address allocated to that process which maps logical address to its physical address to prevent from accessing any unallocated memory area to be used by that process.This prevents an attacker from reliably jumping to a vulnerable function in memory.

c. enhances user experience - when we write a program, we do not think about the problems of memory allocation or how the data is stored in the registers.It is the job of the kernel to load/clear cpu registers.When the kernel stops the execution of a process, it saves the current contents of several processor registers in the process control block(pcb). These include:

    The program counter (PC) and stack pointer (SP) registers

    The general purpose registers

    The floating point registers

    The processor control registers (Processor Status Word) containing information about the CPU state

    The memory management registers used to keep track of the RAM accessed by the process

When the kernel decides to resume executing a process, it uses the proper process control block fiels to load the CPU registers. Because the stored value of the program counter points to the instruction following the last instruction executed, the process resumes execution at the point where it was stopped.

d.malicious activity,close timer , take complete charge of cpu,affects the functioning of other programs

e. i see no problem , doubtful

====================================================================

2.

=====================================================================

3.
a.
b.
c.
d.
====================================================================
4. 16
====================================================================
5. syscall : application program wants some service from os - hardware specific task,The instruction used machine-specific registers that
store syscall entry point (into kernel code) for every syscall
• Arguments, return value go in other registers as per
convention
   exception : Synchronous – will happen every time an instruction
executes with a given program state, division by 0, bad pointer reference
====================================================================
6.
a. https://stackoverflow.com/questions/26964035/batch-processing-proof-of-the-number-of-jobs-relationship-with-service-time-and 
b. 0.4  dollar/hour
======================================================================
7. slides
======================================================================
8. slides : page 101 of book ; design approaches?

This  overhead  has  to  be  minimized  by  avoiding  usage  of  external  memory  during  context-switching,  so  that  the  deadlines  are  met i.e. output is produced at stipulated time. This   paper   focuses   on   reducing   the   overhead   by   modifying   the   architecture of the processor by adding additional register files in to the existing  register  bank  of  processor  so  that  context  can  be  saved  on  processor   itself,   thereby   additional   clock   cycles   for   storing   and   restoring from memory is eliminated
The  overhead  can  be  reduced  by  migrating  kernel  services  such  as  scheduling,  time  tick  (a  periodic  interrupt  to  keep  track  of  time  during  which  the  scheduler  makes  a  decision)  processing [4][8], and interrupt handling to hardware.
In  this  paper,  the  overhead  is  reduced by restricting the use of memory during context-switching by adding register files  to  the  processor.  This  makes  the  process  to  compute  at  much  faster  rate  thereby  reducing the overhead. 

This  paper  introduced  a  concept  of  restricting  the  process  of  context-switching  to  the  processor itself, without having the need for external memory to store and restores the context  of  tasks,  which  presumably  rules  out  the  extra  time  consumption  due  to  memory  to  hardware  transfer  and  viceversa,  from  overall  execution  time,  thereby  the  efficiency of the OS is improved. This concept proves to be vital in case of Hard Real time  systems  where  deadlines  are  to  be  met,  and  the  output  depends  not  only  on  the  logic  but  also  on  the  time  at  which  it  is  produced  i.,e  in  case  of  time  critical  applications.  This  can  be  further  enhanced  by  avoiding  the  need  of  modifying  the  hardware,  instead,  reducing  the  clock  cycle  consumption  for  to  and  fro  transfer  of  contents from memory to processor. 
The main objective of this paper is to reduce the effect of overhead caused due to context-switching,  so  as  to  meet  the  deadlines  of  Real-time  systems.  Dedicating  register  to  a  thread  will  eliminate  the  need  for  saving  and  restoring  of  context,  but  it  reduces the number of registers available for other threads, potentially increasing their register-memory  traffic  and  slowing  execution  [7].  In  this  paper,  the  overhead  is  reduced by restricting the use of memory during context-switching by adding register files  to  the  processor.  This  makes  the  process  to  compute  at  much  faster  rate  thereby  reducing the overhead. 
======================================================================
9. An
I/O -bound process is one that spends more of its time doing I/O than it spends
doing computations. A CPU -bound process, in contrast, generates I/O requests
infrequently, using more of its time doing computations

eg. i/o : program going through a large file ; cpu : large calculation
1. Search algorithms
2. Video/Audio/Content conversion/compression algorithms
3. Video streaming
4. Graphics processing/rendering e.g games, videos
5. Heavy mathematical computations like matrix multiplication, calculating factorials, finding prime numbers etc.

1. Copying/Moving/Transferring/Downloading files
2. Collecting application/OS/data Snapshots

======================================================================
10. page 106 : a. definition
b. long term less frequent than short term  :frequency of execution
c. some os have no long term 

Long term scheduler is also known as a job scheduler. This scheduler regulates the program and select process from the queue and loads them into memory for execution. It also regulates the degree of multi-programing.

However, the main goal of this type of scheduler is to offer a balanced mix of jobs, like Processor, I/O jobs., that allows managing multiprogramming. 

Medium-term scheduling is an important part of swapping. It enables you to handle the swapped out-processes. In this scheduler, a running process can become suspended, which makes an I/O request.

A running process can become suspended if it makes an I/O request. A suspended processes can't make any progress towards completion. In order to remove the process from memory and make space for other processes, the suspended process should be moved to secondary storage. 

Short term scheduling is also known as CPU scheduler. The main goal of this scheduler is to boost the system performance according to set criteria. This helps you to select from a group of processes that are ready to execute and allocates CPU to one of them. The dispatcher gives control of the CPU to the process selected by the short term scheduler. 

https://www.guru99.com/process-scheduling.html : difference table
======================================================================
11. page 121 explaination of each command

>page 123 code
>slide 25 : os_5.pdf
>code in http://www.csl.mtu.edu/cs4411.ck/www/NOTES/process/shm/example-1.html
>https://www.geeksforgeeks.orgfork-memory-shared-bw-processes-created-using/
>code in folder


======================================================================
12. to reduce the time taken by scheduler to choose and time by dispatcher in shifting data from memory to cpu registers 
======================================================================
13. circular linked list

==========================NEW OUTPUT====================================

(alarm-multiple) Creating 5 threads to sleep 7 times each.
(alarm-multiple) Thread 0 sleeps 10 ticks each time,
(alarm-multiple) thread 1 sleeps 20 ticks each time, and so on.
(alarm-multiple) If successful, product of iteration count and
(alarm-multiple) sleep duration will appear in nondescending order.
(alarm-multiple) thread 0: duration=10, iteration=1, product=10
(alarm-multiple) thread 1: duration=20, iteration=1, product=20
(alarm-multiple) thread 0: duration=10, iteration=2, product=20
(alarm-multiple) thread 2: duration=30, iteration=1, product=30
(alarm-multiple) thread 0: duration=10, iteration=3, product=30
(alarm-multiple) thread 3: duration=40, iteration=1, product=40
(alarm-multiple) thread 1: duration=20, iteration=2, product=40
(alarm-multiple) thread 0: duration=10, iteration=4, product=40
(alarm-multiple) thread 4: duration=50, iteration=1, product=50
(alarm-multiple) thread 0: duration=10, iteration=5, product=50
(alarm-multiple) thread 2: duration=30, iteration=2, product=60
(alarm-multiple) thread 1: duration=20, iteration=3, product=60
(alarm-multiple) thread 0: duration=10, iteration=6, product=60
(alarm-multiple) thread 0: duration=10, iteration=7, product=70
(alarm-multiple) thread 3: duration=40, iteration=2, product=80
(alarm-multiple) thread 1: duration=20, iteration=4, product=80
(alarm-multiple) thread 2: duration=30, iteration=3, product=90
(alarm-multiple) thread 4: duration=50, iteration=2, product=100
(alarm-multiple) thread 1: duration=20, iteration=5, product=100
(alarm-multiple) thread 3: duration=40, iteration=3, product=120
(alarm-multiple) thread 2: duration=30, iteration=4, product=120
(alarm-multiple) thread 1: duration=20, iteration=6, product=120
(alarm-multiple) thread 1: duration=20, iteration=7, product=140
(alarm-multiple) thread 4: duration=50, iteration=3, product=150
(alarm-multiple) thread 2: duration=30, iteration=5, product=150
(alarm-multiple) thread 3: duration=40, iteration=4, product=160
(alarm-multiple) thread 2: duration=30, iteration=6, product=180
(alarm-multiple) thread 4: duration=50, iteration=4, product=200
(alarm-multiple) thread 3: duration=40, iteration=5, product=200
(alarm-multiple) thread 2: duration=30, iteration=7, product=210
(alarm-multiple) thread 3: duration=40, iteration=6, product=240
(alarm-multiple) thread 4: duration=50, iteration=5, product=250
(alarm-multiple) thread 3: duration=40, iteration=7, product=280
(alarm-multiple) thread 4: duration=50, iteration=6, product=300
(alarm-multiple) thread 4: duration=50, iteration=7, product=350

======================= OLD OUTPUT ================================

(alarm-multiple) Creating 5 threads to sleep 7 times each.
(alarm-multiple) Thread 0 sleeps 10 ticks each time,
(alarm-multiple) thread 1 sleeps 20 ticks each time, and so on.
(alarm-multiple) If successful, product of iteration count and
(alarm-multiple) sleep duration will appear in nondescending order.
(alarm-multiple) thread 0: duration=10, iteration=1, product=10
(alarm-multiple) thread 1: duration=20, iteration=1, product=20
(alarm-multiple) thread 0: duration=10, iteration=2, product=20
(alarm-multiple) thread 2: duration=30, iteration=1, product=30
(alarm-multiple) thread 0: duration=10, iteration=3, product=30
(alarm-multiple) thread 0: duration=10, iteration=4, product=40
(alarm-multiple) thread 1: duration=20, iteration=2, product=40
(alarm-multiple) thread 3: duration=40, iteration=1, product=40
(alarm-multiple) thread 4: duration=50, iteration=1, product=50
(alarm-multiple) thread 0: duration=10, iteration=5, product=50
(alarm-multiple) thread 2: duration=30, iteration=2, product=60
(alarm-multiple) thread 0: duration=10, iteration=6, product=60
(alarm-multiple) thread 1: duration=20, iteration=3, product=60
(alarm-multiple) thread 0: duration=10, iteration=7, product=70
(alarm-multiple) thread 3: duration=40, iteration=2, product=80
(alarm-multiple) thread 1: duration=20, iteration=4, product=80
(alarm-multiple) thread 2: duration=30, iteration=3, product=90
(alarm-multiple) thread 4: duration=50, iteration=2, product=100
(alarm-multiple) thread 1: duration=20, iteration=5, product=100
(alarm-multiple) thread 1: duration=20, iteration=6, product=120
(alarm-multiple) thread 2: duration=30, iteration=4, product=120
(alarm-multiple) thread 3: duration=40, iteration=3, product=120
(alarm-multiple) thread 1: duration=20, iteration=7, product=140
(alarm-multiple) thread 2: duration=30, iteration=5, product=150
(alarm-multiple) thread 4: duration=50, iteration=3, product=150
(alarm-multiple) thread 3: duration=40, iteration=4, product=160
(alarm-multiple) thread 2: duration=30, iteration=6, product=180
(alarm-multiple) thread 3: duration=40, iteration=5, product=200
(alarm-multiple) thread 4: duration=50, iteration=4, product=200
(alarm-multiple) thread 2: duration=30, iteration=7, product=210
(alarm-multiple) thread 3: duration=40, iteration=6, product=240
(alarm-multiple) thread 4: duration=50, iteration=5, product=250
(alarm-multiple) thread 3: duration=40, iteration=7, product=280
(alarm-multiple) thread 4: duration=50, iteration=6, product=300
(alarm-multiple) thread 4: duration=50, iteration=7, product=350
(alarm-multiple) end